{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/arko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_extracted = pd.read_csv('../data/reddit_comments_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>team</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>comment</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we are going to win 100 games in a row</td>\n",
       "      <td>Happy cake day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He’s definitely lurking in this sub</td>\n",
       "      <td>Ayyyy. He should feel free to slide into my DM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|11zTEl7fbwml68)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Italian born on May 19th in history</td>\n",
       "      <td>I had to go have a look... Pirlo???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|wYThr3gjSU81Q4cuFY)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>10862</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Hi all,\\n\\nI bought a ticket to Saints vs Chel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>10863</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Saints fans, wanted to get an idea for FPL: wh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>10864</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Is that a bad thing though? Hopefully a season...</td>\n",
       "      <td>agreed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>10865</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>I don't think so. \\n\\nLooking back, he didn't ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>10866</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>agreed!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10867 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         team  \\\n",
       "0               0      Arsenal   \n",
       "1               1      Arsenal   \n",
       "2               2      Arsenal   \n",
       "3               3      Arsenal   \n",
       "4               4      Arsenal   \n",
       "...           ...          ...   \n",
       "10862       10862  Southampton   \n",
       "10863       10863  Southampton   \n",
       "10864       10864  Southampton   \n",
       "10865       10865  Southampton   \n",
       "10866       10866  Southampton   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Calafiori's Instagram Story. Can't wait to see...   \n",
       "1      Calafiori's Instagram Story. Can't wait to see...   \n",
       "2      Calafiori's Instagram Story. Can't wait to see...   \n",
       "3      Calafiori's Instagram Story. Can't wait to see...   \n",
       "4      Calafiori's Instagram Story. Can't wait to see...   \n",
       "...                                                  ...   \n",
       "10862                                   Free Talk Friday   \n",
       "10863                                   Free Talk Friday   \n",
       "10864                                   Free Talk Friday   \n",
       "10865                                   Free Talk Friday   \n",
       "10866                                   Free Talk Friday   \n",
       "\n",
       "                                                selftext  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10862  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10863  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10864  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10865  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10866  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "\n",
       "                                                 comment  \\\n",
       "0                 we are going to win 100 games in a row   \n",
       "1                    He’s definitely lurking in this sub   \n",
       "2                           ![gif](giphy|11zTEl7fbwml68)   \n",
       "3               Best Italian born on May 19th in history   \n",
       "4                       ![gif](giphy|wYThr3gjSU81Q4cuFY)   \n",
       "...                                                  ...   \n",
       "10862  Hi all,\\n\\nI bought a ticket to Saints vs Chel...   \n",
       "10863  Saints fans, wanted to get an idea for FPL: wh...   \n",
       "10864  Is that a bad thing though? Hopefully a season...   \n",
       "10865  I don't think so. \\n\\nLooking back, he didn't ...   \n",
       "10866                                            agreed!   \n",
       "\n",
       "                                                 replies  \n",
       "0                                         Happy cake day  \n",
       "1      Ayyyy. He should feel free to slide into my DM...  \n",
       "2                                                    NaN  \n",
       "3                    I had to go have a look... Pirlo???  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "10862                                                NaN  \n",
       "10863                                                NaN  \n",
       "10864                                            agreed!  \n",
       "10865                                                NaN  \n",
       "10866                                                NaN  \n",
       "\n",
       "[10867 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(clean_comment):\n",
    "    if isinstance(clean_comment, str):\n",
    "        sentiment = vader_analyzer.polarity_scores(clean_comment)\n",
    "        return sentiment['compound']\n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_extracted['clean_comment'] = reddit_data_extracted['comment'].fillna('')  # Replace NaN with an empty string\n",
    "reddit_data_extracted['clean_replies'] = reddit_data_extracted['replies'].fillna('')  # Replace NaN with an empty string\n",
    "reddit_data_extracted['vader_comment_sentiment'] = reddit_data_extracted['clean_comment'].apply(vader_sentiment)\n",
    "reddit_data_extracted['vader_replies_sentiment'] = reddit_data_extracted['clean_replies'].apply(vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_extracted['overall_sentiment'] = (reddit_data_extracted['vader_comment_sentiment'] + reddit_data_extracted['vader_replies_sentiment'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>team</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>comment</th>\n",
       "      <th>replies</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>clean_replies</th>\n",
       "      <th>vader_comment_sentiment</th>\n",
       "      <th>vader_replies_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we are going to win 100 games in a row</td>\n",
       "      <td>Happy cake day</td>\n",
       "      <td>we are going to win 100 games in a row</td>\n",
       "      <td>Happy cake day</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.57890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He’s definitely lurking in this sub</td>\n",
       "      <td>Ayyyy. He should feel free to slide into my DM...</td>\n",
       "      <td>He’s definitely lurking in this sub</td>\n",
       "      <td>Ayyyy. He should feel free to slide into my DM...</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.51555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|11zTEl7fbwml68)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|11zTEl7fbwml68)</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best Italian born on May 19th in history</td>\n",
       "      <td>I had to go have a look... Pirlo???</td>\n",
       "      <td>Best Italian born on May 19th in history</td>\n",
       "      <td>I had to go have a look... Pirlo???</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.31845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Calafiori's Instagram Story. Can't wait to see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|wYThr3gjSU81Q4cuFY)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>![gif](giphy|wYThr3gjSU81Q4cuFY)</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>10862</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Hi all,\\n\\nI bought a ticket to Saints vs Chel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi all,\\n\\nI bought a ticket to Saints vs Chel...</td>\n",
       "      <td></td>\n",
       "      <td>-0.3491</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.17455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>10863</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Saints fans, wanted to get an idea for FPL: wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saints fans, wanted to get an idea for FPL: wh...</td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>10864</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>Is that a bad thing though? Hopefully a season...</td>\n",
       "      <td>agreed!</td>\n",
       "      <td>Is that a bad thing though? Hopefully a season...</td>\n",
       "      <td>agreed!</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>10865</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>I don't think so. \\n\\nLooking back, he didn't ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don't think so. \\n\\nLooking back, he didn't ...</td>\n",
       "      <td></td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.40080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>10866</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Free Talk Friday</td>\n",
       "      <td>Yes it's back!  \\n\\nTalk about anything and ev...</td>\n",
       "      <td>agreed!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>agreed!</td>\n",
       "      <td></td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.16910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10867 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         team  \\\n",
       "0               0      Arsenal   \n",
       "1               1      Arsenal   \n",
       "2               2      Arsenal   \n",
       "3               3      Arsenal   \n",
       "4               4      Arsenal   \n",
       "...           ...          ...   \n",
       "10862       10862  Southampton   \n",
       "10863       10863  Southampton   \n",
       "10864       10864  Southampton   \n",
       "10865       10865  Southampton   \n",
       "10866       10866  Southampton   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Calafiori's Instagram Story. Can't wait to see...   \n",
       "1      Calafiori's Instagram Story. Can't wait to see...   \n",
       "2      Calafiori's Instagram Story. Can't wait to see...   \n",
       "3      Calafiori's Instagram Story. Can't wait to see...   \n",
       "4      Calafiori's Instagram Story. Can't wait to see...   \n",
       "...                                                  ...   \n",
       "10862                                   Free Talk Friday   \n",
       "10863                                   Free Talk Friday   \n",
       "10864                                   Free Talk Friday   \n",
       "10865                                   Free Talk Friday   \n",
       "10866                                   Free Talk Friday   \n",
       "\n",
       "                                                selftext  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10862  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10863  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10864  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10865  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "10866  Yes it's back!  \\n\\nTalk about anything and ev...   \n",
       "\n",
       "                                                 comment  \\\n",
       "0                 we are going to win 100 games in a row   \n",
       "1                    He’s definitely lurking in this sub   \n",
       "2                           ![gif](giphy|11zTEl7fbwml68)   \n",
       "3               Best Italian born on May 19th in history   \n",
       "4                       ![gif](giphy|wYThr3gjSU81Q4cuFY)   \n",
       "...                                                  ...   \n",
       "10862  Hi all,\\n\\nI bought a ticket to Saints vs Chel...   \n",
       "10863  Saints fans, wanted to get an idea for FPL: wh...   \n",
       "10864  Is that a bad thing though? Hopefully a season...   \n",
       "10865  I don't think so. \\n\\nLooking back, he didn't ...   \n",
       "10866                                            agreed!   \n",
       "\n",
       "                                                 replies  \\\n",
       "0                                         Happy cake day   \n",
       "1      Ayyyy. He should feel free to slide into my DM...   \n",
       "2                                                    NaN   \n",
       "3                    I had to go have a look... Pirlo???   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10862                                                NaN   \n",
       "10863                                                NaN   \n",
       "10864                                            agreed!   \n",
       "10865                                                NaN   \n",
       "10866                                                NaN   \n",
       "\n",
       "                                           clean_comment  \\\n",
       "0                 we are going to win 100 games in a row   \n",
       "1                    He’s definitely lurking in this sub   \n",
       "2                           ![gif](giphy|11zTEl7fbwml68)   \n",
       "3               Best Italian born on May 19th in history   \n",
       "4                       ![gif](giphy|wYThr3gjSU81Q4cuFY)   \n",
       "...                                                  ...   \n",
       "10862  Hi all,\\n\\nI bought a ticket to Saints vs Chel...   \n",
       "10863  Saints fans, wanted to get an idea for FPL: wh...   \n",
       "10864  Is that a bad thing though? Hopefully a season...   \n",
       "10865  I don't think so. \\n\\nLooking back, he didn't ...   \n",
       "10866                                            agreed!   \n",
       "\n",
       "                                           clean_replies  \\\n",
       "0                                         Happy cake day   \n",
       "1      Ayyyy. He should feel free to slide into my DM...   \n",
       "2                                                          \n",
       "3                    I had to go have a look... Pirlo???   \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "10862                                                      \n",
       "10863                                                      \n",
       "10864                                            agreed!   \n",
       "10865                                                      \n",
       "10866                                                      \n",
       "\n",
       "       vader_comment_sentiment  vader_replies_sentiment  overall_sentiment  \n",
       "0                       0.5859                   0.5719            0.57890  \n",
       "1                       0.2960                   0.7351            0.51555  \n",
       "2                       0.0000                   0.0000            0.00000  \n",
       "3                       0.6369                   0.0000            0.31845  \n",
       "4                       0.0000                   0.0000            0.00000  \n",
       "...                        ...                      ...                ...  \n",
       "10862                  -0.3491                   0.0000           -0.17455  \n",
       "10863                   0.0000                   0.0000            0.00000  \n",
       "10864                   0.3818                   0.3382            0.36000  \n",
       "10865                   0.8016                   0.0000            0.40080  \n",
       "10866                   0.3382                   0.0000            0.16910  \n",
       "\n",
       "[10867 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have all the labels for our data. We now wish to run our analysis on this to see what we get\n",
    "reddit_data_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorisation:\n",
    "reddit_data_extracted['category'] = np.where(reddit_data_extracted['overall_sentiment'] >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comment, clean_replies, sentiment = list(reddit_data_extracted['clean_comment']), list(reddit_data_extracted['clean_replies']), list(reddit_data_extracted['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reddit_data_extracted[['clean_comment','clean_replies','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data['category'] == 1]\n",
    "# data_neut = data[data['category'] == 0]\n",
    "data_neg = data[data['category'] == -1]\n",
    "\n",
    "dataset = pd.concat([data_pos, data_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "STOPWORDS = set(stopwordlist)\n",
    "punctuations_list = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all clean_comment to lowercase for uniformity\n",
    "dataset['clean_comment']=dataset['clean_comment'].str.lower()\n",
    "dataset['clean_replies']=dataset['clean_replies'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Now we create a few function to help us with cleaning of data\n",
    "1. Removing stopwords from the clean_comment\n",
    "2. Defining and applying a function to remove punctuation\n",
    "3. Removing any urls from the clean_comment\n",
    "4. Removing any numbers present in our clean_comment\n",
    "\n",
    "'''\n",
    "def cleaning_stopwords(clean_comment):\n",
    "    return \" \".join([word for word in str(clean_comment).split() if word not in STOPWORDS])\n",
    "\n",
    "def cleaning_punctuations(clean_comment):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return clean_comment.translate(translator)\n",
    "\n",
    "# def cleaning_repeating_char(clean_comment):\n",
    "#     return re.sub(r'(.)1+', r'1', clean_comment)\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "\n",
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_comment'] = dataset['clean_comment'].apply(lambda clean_comment: cleaning_stopwords(clean_comment))\n",
    "dataset['clean_comment']= dataset['clean_comment'].apply(lambda x: cleaning_punctuations(x))\n",
    "dataset['clean_comment'] = dataset['clean_comment'].apply(lambda x: cleaning_URLs(x))\n",
    "dataset['clean_comment'] = dataset['clean_comment'].apply(lambda x: cleaning_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_replies'] = dataset['clean_replies'].apply(lambda clean_replies: cleaning_stopwords(clean_replies))\n",
    "dataset['clean_replies']= dataset['clean_replies'].apply(lambda x: cleaning_punctuations(x))\n",
    "dataset['clean_replies'] = dataset['clean_replies'].apply(lambda x: cleaning_URLs(x))\n",
    "dataset['clean_replies'] = dataset['clean_replies'].apply(lambda x: cleaning_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index for consistency \n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# created a function for lemmatizing the clean_column\n",
    "def lemmatizer_on_clean_column(data):\n",
    "    clean_column = [lm.lemmatize(word) for word in data]\n",
    "    return clean_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_comment'] = dataset['clean_comment'].apply(tokenizer.tokenize)\n",
    "dataset['clean_comment'] = dataset['clean_comment'].apply(lambda x: lemmatizer_on_clean_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_replies'] = dataset['clean_replies'].apply(tokenizer.tokenize)\n",
    "dataset['clean_replies'] = dataset['clean_replies'].apply(lambda x: lemmatizer_on_clean_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  10000\n"
     ]
    }
   ],
   "source": [
    "#comment:\n",
    "X_comment = dataset.clean_comment\n",
    "y = dataset.category\n",
    "\n",
    "# Converting tokenized clean_comment back to strings\n",
    "X_comment = X_comment.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Separating the 80% data for training data and 20% for testing data with a set random state to ensure same results\n",
    "X_train_comment, X_test_comment, y_train, y_test = train_test_split(X_comment,y,test_size = 0.2, random_state =26105111)\n",
    "\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "vectoriser.fit(X_train_comment)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names_out()))\n",
    "\n",
    "X_train_comment = vectoriser.transform(X_train_comment)\n",
    "X_test_comment  = vectoriser.transform(X_test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7813    1\n",
       "2343    1\n",
       "3202    1\n",
       "6946    1\n",
       "2859    1\n",
       "       ..\n",
       "9336   -1\n",
       "3662    1\n",
       "2527    1\n",
       "1014    1\n",
       "793     1\n",
       "Name: category, Length: 2174, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  10000\n"
     ]
    }
   ],
   "source": [
    "#comment:\n",
    "X_replies = dataset.clean_replies\n",
    "y = dataset.category\n",
    "\n",
    "# Converting tokenized clean_comment back to strings\n",
    "X_replies = X_replies.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Separating the 80% data for training data and 20% for testing data with a set random state to ensure same results\n",
    "X_train_replies, X_test_replies, y_train, y_test = train_test_split(X_replies,y,test_size = 0.2, random_state =26105111)\n",
    "\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "vectoriser.fit(X_train_replies)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names_out()))\n",
    "\n",
    "X_train_replies = vectoriser.transform(X_train_replies)\n",
    "X_test_replies  = vectoriser.transform(X_test_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Evaluate_comment(model):\n",
    "    y_pred_comment = model.predict(X_test_comment)\n",
    "\n",
    "def model_Evaluate_replies(model):\n",
    "    y_pred_replies = model.predict(X_test_replies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNBmodel_comment = BernoulliNB()\n",
    "BNBmodel_comment.fit(X_train_comment, y_train)\n",
    "model_Evaluate_comment(BNBmodel_comment)\n",
    "y_pred_comment1 = BNBmodel_comment.predict(X_test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_comment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNBmodel_replies = BernoulliNB()\n",
    "BNBmodel_replies.fit(X_train_replies, y_train)\n",
    "model_Evaluate_replies(BNBmodel_replies)\n",
    "y_pred_replies1 = BNBmodel_replies.predict(X_test_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_replies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_y_pred = (y_pred_replies1 + y_pred_comment1)/2\n",
    "combined_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.67      0.07      0.12       559\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.79      0.88      0.84      1615\n",
      "\n",
      "    accuracy                           0.67      2174\n",
      "   macro avg       0.49      0.32      0.32      2174\n",
      "weighted avg       0.76      0.67      0.65      2174\n",
      "\n",
      "[[  38  144  377]\n",
      " [   0    0    0]\n",
      " [  19  167 1429]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, combined_y_pred))\n",
    "cf_matrix = confusion_matrix(y_test, combined_y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRmodel_comment  = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel_comment.fit(X_train_comment, y_train)\n",
    "model_Evaluate_comment(LRmodel_comment)\n",
    "y_pred_comment2 = LRmodel_comment.predict(X_test_comment)\n",
    "\n",
    "LRmodel_replies  = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel_replies.fit(X_train_replies, y_train)\n",
    "model_Evaluate_comment(LRmodel_replies)\n",
    "y_pred_replies2 = LRmodel_replies.predict(X_test_replies)\n",
    "\n",
    "combined_y_pred_2 = (y_pred_replies2 + y_pred_comment2)/2\n",
    "combined_y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.02      0.04       559\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.81      0.97      0.88      1615\n",
      "\n",
      "    accuracy                           0.72      2174\n",
      "   macro avg       0.60      0.33      0.31      2174\n",
      "weighted avg       0.86      0.72      0.67      2174\n",
      "\n",
      "[[  12  181  366]\n",
      " [   0    0    0]\n",
      " [   0   56 1559]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arko/VSC/NLP_ECE684/final_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, combined_y_pred_2))\n",
    "cf_matrix = confusion_matrix(y_test, combined_y_pred_2)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
